# 🪄 Lumos
<p align="center">
  <a href="">
    <img src="https://img.shields.io/badge/🌐-Website-red">
  </a>
  <a href="">
    <img src="https://img.shields.io/badge/📝-Paper-blue">
  </a>
  <a href="">
    <img src="https://img.shields.io/badge/🤗-Data-orange">
  </a>
  <a href="">
    <img src="https://img.shields.io/badge/🤗-Model-green">
  </a> 
</p>

We introduce 🪄**Lumos**, Language Agents with **Unified** Formats, **Modular** Design, and **Open-Source** LLMs. **Lumos** unifies a suite of complex interactive tasks and achieves competitive performance with GPT-4/3.5-based and larger open-source agents. 

**Lumos** has following features:
* 🧩 **Modular Architecture**:
  - **Lumos** consists planning, grounding, and execution modules built based on open LLMs such as LLAMA-2.
* 🌍 **Diverse Training Data**:
  - **Lumos** is trained with ~40K high-quality annotations from ground-truth reasoning steps in existing benchmarks with GPT-4. 
* 🚀 **Competitive Performance**:
  - 🚀 **Lumos** outperforms **GPT-4/3.5-based** agents on complex QA and web agent tasks, and larger open agents on maths tasks.
  - 🚀 **Lumos** performs better than open agent baseline formulations including **chain-of-thoughts** and **unmodularized** training.
  - 🚀 **Lumos** surpasses larger open LLM agents and domain-specific agents on an unseen task, WebShop.

## 🔥 News
- **[2023, Oct ]** We release the important items for training and evaluating **Lumos**:
  - 💻 **Lumos** code for annotation generation, training and evaluation
  - 🤗 **Lumos** checkpoints with 7B model size
  - 🤗 **Lumos** training annotations and their raw data
 
## 🧩 Architecture


## Training Paradigm
